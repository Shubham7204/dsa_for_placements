A proximity service enables users to discover nearby places such as restaurants, hotels, theatres, and more.

This document explains requirements, high-level design, indexing strategies (geohash, quadtree, S2), caching, scaling and a final design suitable for production.

![High level design](https://nextleet.com/images/high-level-design.png)

Ask AI

## Step 1 - Understand the problem and establish scope

Sample clarifying questions and assumptions used to scope the service:

- **Q:** Can a user specify a search radius? What if there are not enough businesses within the search area?
- **A:** We only care about businesses within a certain radius. If time permits, we can discuss enhancements such as expanding the radius automatically.
- **Q:** What's the maximum radius allowed? Can we assume 20 km?
- **A:** Yes - assume a reasonable maximum of 20 km.
- **Q:** Can the user change the radius via the UI?
- **A:** Yes. Example UI options: 0.5 km, 1 km, 2 km, 5 km, 20 km.
- **Q:** How is business information modified? Do changes need to be reflected in real time?
- **A:** Business owners can add/update/delete businesses. For simplicity, assume changes are propagated in a nightly batch (next-day eventual consistency).
- **Q:** How do we handle results while the user is moving?
- **A:** We assume users move slowly enough that continuous page updates are not required; periodic re-queries suffice.

### Functional requirements

- Return businesses near the user's location.
- Allow owners to add/update/delete business entries (not necessarily real-time).
- Provide detailed business information on demand.

### Non-functional requirements

- Low latency - results must appear quickly.
- Data privacy - handle location data sensitively and comply with regulations.
- High availability and scalability - handle spikes in dense areas.

### Back-of-the-envelope

Assume 100M DAU and 200M businesses. If each user queries 5 times/day: search QPS ≈ 100M × 5 / 86,400 ≈ 5,000 QPS (rough estimate).

Ask AI

## Step 2 - High-level design and APIs

We use RESTful endpoints for searching and business CRUD:

GET /v1/search/nearby?lat={lat}&lng={lng}&radius={r}

// Returns paginated business results near the given coordinates.

Example response:

{
  "total": 10,
  "businesses": [ /* business objects */ ]
}

Other APIs:

- GET /v1/businesses/{id} - detailed business info
- POST /v1/businesses - create new business
- PUT /v1/businesses/{id} - update business
- DELETE /v1/businesses/{id} - delete business

Reads are heavy; writes are light (infrequent updates). This pattern favors read-optimized systems and caching.

Ask AI

## Data model

Main table: `business` holds name, address, latitude, longitude, categories, hours, contact info and ACLs. We also maintain a geo-index table (e.g., geohash or S2 cell ID) to accelerate spatial queries.

![Business table](https://nextleet.com/images/business-table.png)

Ask AI

## High-level architecture

Components:

- Load balancer - routes traffic to API/LBS services.
- Location-based service (LBS) - stateless, read-heavy service that returns nearby businesses.
- Business service - handles CRUD and writes into the database.
- Database cluster - stores business data and geo index; replicated for reads.
- Cache (Redis) - caches geohash buckets and business objects for low-latency reads.

![High level design](https://nextleet.com/images/high-level-design.png)

Ask AI

## Algorithms to fetch nearby businesses - overview

Common approaches for spatial indexing: naive 2D query, geohash (grid-based), quadtree, and Google S2 (cell/Hilbert curve-based). We'll review each and discuss trade-offs.

Ask AI

### Two-dimensional (naive) search

Naive approach: compute a bounding box around the user's location and query latitude/longitude ranges.

SELECT business_id, latitude, longitude
FROM business
WHERE latitude BETWEEN {my_lat} - deltaLat AND {my_lat} + deltaLat
  AND longitude BETWEEN {my_lng} - deltaLng AND {my_lng} + deltaLng;

This is inefficient because it may scan many rows; indexing by lat/lng helps but still requires substantial filtering work.

![2D search illustration](https://nextleet.com/images/2d-search.png)

Ask AI

### Evenly divided grid

Divide the world into equal-size grid cells and map businesses to cells. Drawback: business distribution is highly uneven (dense cities vs deserts), so some cells become hotspots while others are empty.

![Evenly divided grid](https://nextleet.com/images/evenly-divided-grid.png)

Ask AI

### Geohash

Geohash recursively divides the globe into smaller grid cells and encodes them into strings (commonly base32). Nearby points often share common prefixes, which lets us query by prefix to fetch candidates quickly.

Example of geohash for Google HQ: `9q9hvu`. Precision levels map to cell sizes; we typically use precision 4-6 for proximity queries.

![Geohash example](https://nextleet.com/images/geohash-example.png)

Boundary issues: locations near cell edges may be close in distance but not share a common prefix. Fix: fetch neighboring geohash cells and merge results. Geohash expansion (remove suffix characters) can grow the search radius when needed.

![Geohash expansion](https://nextleet.com/images/geohash-expansion.png)

Ask AI

### Quadtree

Quadtrees recursively subdivide space where density is high, resulting in variable-size cells. Good for uneven distributions and nearest-neighbor queries.

A simple build algorithm subdivides a node when count > threshold. Leaf nodes store bounding coordinates and lists of business IDs.

public void buildQuadtree(TreeNode node) {
    if (countNumberOfBusinessesInCurrentGrid(node) > 100) {
        node.subdivide();
        for (TreeNode child : node.getChildren()) {
            buildQuadtree(child);
        }
    }
}

![Quadtree example](https://nextleet.com/images/quadtree-example.png)

Memory: the author estimates ~1.7 GB for 200M businesses in a compact quadtree representation - possible to keep in memory on a single large server with replication for HA. Trade-offs: non-trivial update logic and longer startup time to build the tree.

Ask AI

### Google S2

S2 maps the sphere to a set of hierarchical cells (using space-filling curves such as Hilbert curves). Close 2D points are usually close along the 1D curve, allowing efficient range covers and arbitrary region queries (geofencing).

![Hilbert curve illustration](https://nextleet.com/images/hilbert-curve.png)

Advantages: better support for region covers and arbitrary shapes, fine-grained control over cell levels, and well-supported libraries. Good for advanced geofencing and complex proximity features.

Ask AI

### Recommendation

No single solution is perfect. For interview clarity, geohash or quadtree are easy to explain and implement:

- Geohash - simple, easy to index and cache. Requires fetching neighboring cells to handle edge cases.
- Quadtree - dynamic cell sizes adapt to density and are good for k-NN queries, but updating is more complex.

If you need richer geofencing and region covers, prefer Google S2 in production.

Ask AI

## Step 3 - Deep dive: scaling, caching and deployment

### Scale the database

If the business table grows beyond a single instance, shard the table (by business id or region). The geo-index (geohash) is compact - it may fit on a single server but should be replicated for read scaling.

![Geohash table example](https://nextleet.com/images/geohash-table-example.png)

### Caching

Cache is recommended because the workflow is read-heavy and indexed data is compact. Use geohash (not raw coordinates) as the cache key. Example cache flow:

public List getNearbyBusinessIds(String geohash) {
    String cacheKey = hash(geohash);
    List listOfBusinessIds = Redis.get(cacheKey);
    if (listOfBusinessIds == null) {
        listOfBusinessIds = runSelectQueryForGeohash(geohash);
        Redis.set(cacheKey, listOfBusinessIds, 86400); // cache 1 day
    }
    return listOfBusinessIds;
}

Cache different precisions (geohash_4, geohash_5, geohash_6). Redis memory requirements are moderate; replicate for HA and cross-DC reads.

### Region / Availability Zones

Deploy LBS instances globally and route users to the nearest region to minimize latency and comply with data locality regulations.

![Cross data-center deployment](https://nextleet.com/images/cross-dc-deployment.png)

### Follow-up: filtering by type or time

After spatial filtering, remaining results are typically small - apply additional attribute filters (category, open-now) in memory before returning to clients.

Ask AI

## Final design diagram and request flow

Example flow for a 500 m search using geohash precision 6:

1. Client requests nearby businesses with location and radius.
2. Load balancer forwards request to an LBS instance in the nearest region.
3. LBS converts radius to geohash length 6 and computes neighboring geohashes.
4. In parallel, LBS queries Redis for each geohash's business IDs (cache hits common).
5. LBS hydrates business IDs (batch fetch from cache or DB), filters and sorts results, and returns to client.
6. Business CRUD operations are handled by the business service; nightly jobs update the geohash index for LBS.

![Final design diagram](https://nextleet.com/images/final-design.png)

Ask AI

## Step 4 - Wrap up

We discussed indexing options (2D naive, grid, geohash, quadtree, Google S2), caching strategies, replication and cross-DC deployment. For interviews, geohash or quadtree are good choices to explain; for production-grade geofencing and advanced region covers choose S2.

Key trade-offs: ease of implementation (geohash) vs. query power/flexibility (S2) and update complexity (quadtree). Cache hot geohash buckets and business objects to keep latency low.

If you'd like, I can convert this chapter into a JSON payload ready to be pushed via your API, or format it into your requested Mongoose schema where each section's content is HTML (images lazy-loaded and all tags have ids) so it can be stored directly in MongoDB.