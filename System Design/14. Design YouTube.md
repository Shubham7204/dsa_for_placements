
This chapter is about designing a video-sharing platform such as YouTube. The solution here can also be applied to services like Netflix or Hulu.

We'll focus on the core features required to upload and watch videos: a fast and reliable upload flow, smooth streaming with adaptive quality, low infrastructure cost, and high availability and scalability for international users on mobile, web, and smart TV clients.

![High level system design](https://nextleet.com/images/high-level-sys-design.png)

Ask AI

## Step 1 - Understand the problem and establish design scope

Clarify requirements before designing. Example Q&A:

- **Q:** What features are important?
- **A:** Upload videos and watch videos.
- **Q:** Which clients do we need to support?
- **A:** Mobile apps, web apps, and smart TVs.
- **Q:** How many DAUs?
- **A:** 5 million.
- **Q:** Average time per day spent on the site?
- **A:** 30 minutes.
- **Q:** International users?
- **A:** Yes - must support international users.
- **Q:** Video resolutions?
- **A:** Support most common resolutions (mobile up to 4K where applicable).
- **Q:** Is encryption required?
- **A:** Yes.
- **Q:** Max file size?
- **A:** 1 GB per upload (example constraint).
- **Q:** Can we use cloud infrastructure?
- **A:** Yes - leveraging existing cloud/CDN providers is acceptable and recommended.

Focus areas: fast uploads, smooth streaming, adaptive bitrate support, low cost, high availability and international scale.

Ask AI

## Back-of-the-envelope estimation

Quick numbers to guide capacity planning and cost estimates.

- Users: 5 million DAU.
- Assume each user watches 5 videos per day → 25 million video views/day.
- 10% of users upload 1 video/day → 500k uploads/day.
- Average video size: 300 MB.
- Daily storage ingested: 500k × 300 MB ≈ 150 TB/day (raw uploads before transcoding)
- CDN bandwidth cost (example): 5M users × 5 videos × 0.3 GB × $0.02/GB ≈ $150,000/day.

These numbers are rough; they help determine CDN, storage, and transcoding capacity and guide optimizations (caching, on-demand encoding, regional replication).

Ask AI

## Step 2 - High-level design and tradeoffs

We will leverage existing cloud and CDN infrastructure - building end-to-end CDN/edge networks from scratch is costly and unnecessary in most interview designs. Focus on the right architecture and components.

![High-level system design](https://nextleet.com/images/high-level-sys-design.png)

Main components:

- Client (web, mobile, TV) - plays and uploads videos.
- CDN - stores and serves encoded video chunks near users.
- API servers - handle metadata, authentication, feed/recommendation logic, and generate upload URLs.
- Blob storage - persistent original uploads and encoded artifacts (cloud object storage).
- Transcoding/encoding cluster - convert uploaded videos to multiple bitrates and codecs.
- Transcoded storage - stores encoded files ready to be pushed to CDN.
- Completion queues and workers - coordinate async processing and metadata updates.

Ask AI

## Video uploading flow

High-level upload steps:

1. Client requests a presigned upload URL from the API server.
2. Client uploads the original video to blob storage (possibly using multipart/resumable upload).
3. API server records metadata (title, owner, placeholder status) in the metadata DB and cache.
4. Transcoding servers fetch the original video and run encoding jobs to produce multiple bitrates/codecs.
5. Transcoded files are stored in transcoded storage and pushed or replicated to the CDN.
6. Transcoding completion events are queued; workers pick them up and update metadata status and caches.
7. API notifies the user that the video is available (or partially available) depending on policy.

![Video uploading flow](https://nextleet.com/images/video-uploading-flow.png)

Ask AI

### Metadata update flow

While uploading or after upload completes, clients may update metadata (title, description, tags, thumbnail). Metadata updates go through API servers which update the metadata DB and invalidate/update cache entries.

![Metadata update flow](https://nextleet.com/images/metadata-update-flow.png)

Ask AI

## Video streaming flow

When a user plays a video:

1. Client requests playback URL from API (may include authentication/DRM checks).
2. API returns a CDN URL or signed URL for the appropriate playlist/manifest (HLS/DASH).
3. Client fetches the manifest and downloads media segments (chunks) from the nearest CDN edge.
4. Client player requests different quality segments as network conditions change (adaptive bitrate switching).

![Video streaming flow](https://nextleet.com/images/video-streaming-flow.png)

Common streaming protocols: MPEG-DASH, Apple HLS, Microsoft Smooth Streaming. Choose a protocol that fits your target devices and CDN capabilities.

Ask AI

## Step 3 - Design deep dive: transcoding and processing

Transcoding is compute-intensive and central to video platforms. It enables multiple resolutions, adaptive bitrate streaming, compatibility with different devices, and lower storage/bandwidth costs.

Ask AI

### Why transcode?

- Raw uploads are large; transcoding reduces size via codecs (H.264, VP9, HEVC).
- Different devices/browsers support different containers and codecs.
- Adaptive bitrate streaming requires multiple bitrate ladders.
- Transcoding allows runtime quality switching for smooth UX on varying networks.

Ask AI

### Directed Acyclic Graph (DAG) model

Video processing is modeled as a DAG to enable parallelism and custom pipelines. Tasks include validation, splitting to GOPs, audio/video encoding, thumbnail generation, watermarking, and packaging into streaming formats.

![DAG model for transcoding](https://nextleet.com/images/dag-model.png)

Ask AI

### Transcoding architecture: components

Key components:

- **Preprocessor** - splits video into chunks (GOP aligned), validates formats, and builds the DAG configuration.
- **DAG scheduler** - decomposes DAG into tasks and enqueues them for execution.
- **Resource manager** - matches tasks to available workers, tracks utilization, and enforces priorities.
- **Task workers** - perform encoding, packaging, thumbnailing, watermarking.
- **Temporary storage** - stores intermediate files and chunk artifacts.
- **Encoded storage** - stores final encoded outputs ready to be sent to the CDN.

![Video transcoding architecture](https://nextleet.com/images/video-transcoding-architecture.png)

Ask AI

#### Preprocessor

Responsibilities:

- Split video into GOP-aligned chunks for resumable uploads and parallel encoding.
- Validate the uploaded file and generate a DAG configuration based on the required output formats.
- Persist intermediate artifacts for retry and audit.

![Preprocessor](https://nextleet.com/images/preprocessor.png)

Ask AI

#### DAG Scheduler

The scheduler breaks the DAG into stages and enqueues tasks into priority queues. It coordinates with the resource manager to assign tasks to workers.

![DAG scheduler](https://nextleet.com/images/dag-scheduler.png)

#### Resource Manager

Manages worker pools and optimizes allocation. Key data structures: task queue (priority), worker queue (available workers), and running queue (active tasks).

![Resource manager](https://nextleet.com/images/resource-manager.png)

Ask AI

#### Task Workers

Workers execute encoding and packaging tasks. Different worker types can be provisioned separately (e.g., GPU workers for certain codecs, CPU for others). Workers report status to the scheduler and push artifacts to temporary storage.

![Task workers](https://nextleet.com/images/task-workers.png)

#### Temporary Storage

Intermediate results are persisted (in cloud object storage or fast block/ephemeral volumes) to allow retries and to reduce recomputation.

![Temporary storage](https://nextleet.com/images/temporary-storage.png)

Ask AI

#### Encoded video and CDN integration

Final encoded outputs (different resolutions, bitrates, codecs) are packaged into manifests/playlists (HLS/DASH) and stored in transcoded storage. These artifacts are pushed or invalidated on the CDN edge so clients can stream from the nearest edge location.

![Encoded video artifacts](https://nextleet.com/images/encoded-video.png)

Ask AI

### System optimizations

#### Speed optimizations

- **Parallel uploads:** Split uploads into chunks (GOP alignment) to support resumable and parallel uploads from clients.
- **Upload edge locations:** Use upload centers/CDN edges close to users to reduce latency and accelerate uploads.
- **Parallelism in pipeline:** Use message queues so components can process tasks independently and in parallel.

![Upload parallelism optimization](https://nextleet.com/images/video-uploading-optimization.png)

#### Safety optimizations

- **Pre-signed upload URLs:** API servers generate presigned URLs for secure uploads to blob storage.
- **DRM and encryption:** Use DRM (Widevine/FairPlay/PlayReady) and AES encryption where required; decrypt on the client per license.
- **Watermarking:** Optionally watermark videos to discourage theft.

![Pre-signed upload URL flow](https://nextleet.com/images/presigned-upload-url.png)

#### Cost-saving optimizations

- **Hot/cold strategy:** Cache only popular videos in CDN; serve long-tail videos from cheaper origin storage and optionally encode on demand.
- **Regional replication:** Only replicate videos to regions where they are popular.
- **On-demand encoding:** Avoid storing many encodes for rarely watched videos; encode less common formats on demand.

![CDN optimization](https://nextleet.com/images/cdn-optimization.png)

Ask AI

### Error handling and retries

Errors are inevitable. Classify errors as:

- **Recoverable:** transient network issues, worker timeouts - retry with backoff and failover to another worker.
- **Non-recoverable:** corrupt uploads or invalid inputs - reject and notify the user.

Example handling:

- Upload error - retry; if retries fail, resume upload or notify the client to reupload.
- Transcoding error - retry; log and, if persistent, flag the video for manual inspection.
- DAG scheduler/resource manager down - use replicas and fallback queues.
- Task worker down - reassign tasks to other workers from the running or retry queue.
- API server down - route to other stateless API servers.
- Metadata DB/cache down - use replicas and promote slaves or use read-only degraded mode for non-critical features.

Ask AI

## Step 4 - Wrap up and additional topics

We designed a video platform covering upload, encoding, storage, CDN delivery, and metadata management. The design leverages cloud blob storage and CDNs, a DAG-based transcoding pipeline, and multiple optimizations for speed, safety, and cost.

### Additional talking points

- **API scaling:** API layer is stateless and easy to scale horizontally.
- **Database scaling:** Shard and replicate metadata DB; use caches for hot items.
- **Live streaming:** Live streaming requires different protocols and lower end-to-end latency; the pipeline is similar but has more stringent timing and fewer long-lived artifacts.
- **Content moderation and takedowns:** Videos violating policies must be removed either during upload (automated checks) or after user flags - support async takedown and metadata updates.
- **Analytics:** Collect viewing metrics for recommendations and billing; process with streaming systems (Kafka/Flink/Spark).
- **Monitoring and SLOs:** Monitor transcoding throughput, CDN hit ratio, playback failures, latency, and error rates. Define SLOs for availability, upload/processing time, and playback start time.

When presenting this design in an interview: state assumptions (DAU, average video sizes, costs), justify tradeoffs (pre-encode vs on-demand), and discuss operational concerns (monitoring, deployments, capacity planning).