We will design a chat system similar to Messenger, WhatsApp, etc. It is important to nail down exact requirements because chat systems can differ a lot - for example, those focused on group chats versus one-on-one conversations.

This document walks through clarifying requirements, proposing a high-level design, and doing deep dives into key components such as service discovery, message flows, and presence.

Key goals for this design: low delivery latency for messages, support for both one-on-one and small group chats, online presence indicators, multi-device login for the same account, push notifications, and the ability to store chat history indefinitely.

![Store and relay message](https://nextleet.com/images/store-relay-message.png)

 

## Step 1 - Understand the problem and establish design scope

Clarify requirements up front - chat systems have many variants. Below is an example Q&A that defines the scope we will design for.

- **Chat types:** Support both one-on-one conversations and group chats.
- **Clients:** Mobile and web clients.
- **Scale:** Target scale is 50 million daily active users (DAU).
- **Group size:** Up to 100 members per group.
- **Features:** 1-on-1 and group chats, online presence indicator, text messages only for now.
- **Message size:** Text messages up to 100,000 characters.
- **Encryption:** End-to-end encryption is not required (may be discussed later).
- **Retention:** Chat history must be stored indefinitely.

Primary functionality to focus on: reliable, low-latency one-on-one chat; small group chat support; presence; multi-device sync; push notifications; persistent history.

 

## Step 2 - High-level design and communication options

Clients (mobile or web) do not connect to each other directly - all communication goes through servers. We must choose how to deliver real-time messages from server to client. Common approaches include polling, long polling, and WebSockets.

### Polling

With polling, the client periodically asks the server for updates. Polling is simple to implement but inefficient - it generates many requests and often returns no new data.

![Polling diagram](https://nextleet.com/images/polling.png)

### Long polling

Long polling keeps an HTTP request open until the server has data to return. It is more efficient than naive polling but still has drawbacks: it can be tricky to detect disconnections, and it causes more overhead than a single persistent connection.

![Long polling diagram](https://nextleet.com/images/long-polling.png)

### WebSocket

WebSocket is the preferred approach for bidirectional, low-latency communication. The connection begins as an HTTP request and is upgraded to a persistent TCP connection so both client and server can push messages to each other. The downside is that servers become stateful and must manage many concurrent connections efficiently.

![Web sockets diagram](https://nextleet.com/images/web-sockets.png)

 

## High-level system components

Our design separates functionality into stateless APIs, stateful chat servers for realtime connections, and third-party integration for push notifications.

### Stateless services

Traditional request/response services (behind a load balancer) handle login, signup, user profile, settings, group management, and other administrative operations. These are horizontally scalable and stateless.

### Stateful chat service

Chat servers maintain persistent connections (WebSockets) with clients for realtime messaging. Because of the persistent connections, these servers are stateful; we need service discovery to assign clients to chat servers and to coordinate load.

### Third-party integration

Push notifications (APNs, FCM) are handled by dedicated notification servers or a notification subsystem; this component is invoked when a recipient is offline.

![High-level chat design](https://nextleet.com/images/high-level-design.png)

 

## Scalability considerations

A single server can serve many connected clients, but at large scale we must distribute connections across many chat servers. For example, with 1 million concurrent clients and 10KB memory per connection, total memory would be ~10GB - but a single process/server is a single point of failure and difficult to scale reliably.

Design goals: avoid single points of failure, shard connections across many chat servers, use service discovery to assign clients, and use message queues and worker pools for asynchronous work such as persistence and fanout.

![Refined high level design](https://nextleet.com/images/refined-high-level-design.png)

 

## Storage choices and chat history

Chat history has unique access patterns: enormous overall volume, recent messages are accessed frequently, and history must be available for search. Read/write ratio is roughly 1:1.

Key-value stores (NoSQL) are commonly used for chat history because they scale horizontally, offer low-latency access, and handle large datasets with many random reads well. Examples used in practice: Facebook uses HBase, Discord uses Cassandra. Relational databases are appropriate for canonical user data (profiles, friendships) while the chat messages themselves often live in a key-value store.

 

## Data models

Message schemas differ for one-on-one and group chats. Use a message id for ordering rather than creation timestamp because messages can have the same timestamp.

### One-on-one message model

A typical row might include: `message_id` (unique, sortable), `from_user_id`, `to_user_id`, `content`, `created_at`, and delivery metadata. The key-value store may use a composite key like `inbox:{user_id}` containing an ordered list of messages.

![One-on-one message table](https://nextleet.com/images/one-on-one-chat-table.png)

### Group chat model

For group chats, use a `channel_id` sharding key, and store messages keyed by `(channel_id, message_id)`. For small groups we may replicate message copies into each participant's inbox to simplify per-user sync. For very large groups, separate approaches are needed to avoid explosion of copies.

![Group chat table](https://nextleet.com/images/group-chat-table.png)

### Message ID generation

Message IDs must be unique and sortable by time. Options include:

- **Database auto-increment** - easy but hard to use in distributed key-value stores.
- **Snowflake (Twitter)** - 64-bit, time-sortable, distributed-friendly.
- **Local sequence per chat** - unique only within a chat; acceptable if ordering is required only per-chat.

Pick an ID strategy based on ordering semantics and distribution requirements. Snowflake is a common choice when a globally sortable ID is desired.

 

## Step 3 - Deep dive: service discovery, message flows, and presence

In interviews you are usually asked to dig deeper into a few components. We'll explore service discovery, messaging flows (1-on-1 and group), message synchronization across devices, and online presence.

 

### Service discovery

Service discovery chooses the best chat server for a client based on geography, server capacity, or other criteria. Apache ZooKeeper, etcd or a custom registry can be used to register available chat servers and their metadata. The discovery service should route a client to an optimal chat server at login.

![Service discovery diagram](https://nextleet.com/images/service-discovery.png)

1. User authenticates via API servers.
2. Service discovery selects a chat server (e.g., based on lowest load or nearest region).
3. Client establishes a WebSocket connection to the selected chat server.

 

### Message flows - one-on-one chat

Typical flow:

1. User A sends a message to their connected chat server (Chat server 1).
2. Chat server 1 obtains a `message_id` from the ID generator.
3. Chat server 1 writes the message to a persistence layer (often via a message-sync queue).
4. If User B is online (connected to Chat server 2), the service forwards the message to Chat server 2 and it is pushed to User B over WebSocket.
5. If User B is offline, the message remains in persistent storage and a push notification is sent via notification servers.

![One-on-one chat flow](https://nextleet.com/images/one-on-one-chat-flow.png)

 

### Message synchronization across devices

A single account may be logged in on multiple devices. Each device maintains a local variable, `cur_max_message_id`, representing the last message it has received. When a device reconnects, the server delivers all messages with `message_id > cur_max_message_id` to bring the device up to date. Messages sent to the account are delivered to all currently connected devices.

![Message sync across devices](https://nextleet.com/images/message-sync.png)

 

### Group chat flow (small groups)

For small groups (â‰¤ 100 members) it is feasible to store a copy of each message in each participant's inbox. This simplifies synchronization because each participant only needs to look at their own inbox for new messages.

Workflow when User A sends a group message:

1. Chat server inserts the message into group storage keyed by `(channel_id, message_id)`.
2. Fanout logic copies the message reference into each participant's inbox queue (or enqueues delivery events per participant).
3. If a participant is online, deliver in realtime; otherwise persist and optionally send a push notification.

![Group chat flow](https://nextleet.com/images/group-chat-flow.png)

For very large groups, copying messages is not feasible - alternative approaches include storing a single canonical message stream per group and letting clients fetch new messages by cursor/range queries.

 

### Online presence

Presence servers manage online/offline status. When a user logs in, their status is marked as online; when they log out, they are marked offline. Handling unexpected disconnects requires heartbeats: clients periodically send heartbeats to the presence servers. If a heartbeat is not received within a threshold, the user is marked offline to avoid flapping.

![User heartbeat](https://nextleet.com/images/user-heartbeat.png)

To inform friends of status changes, use a fanout mechanism: each friend-pair can have a small queue for presence updates. For small friend lists this is efficient; for large groups you may defer presence checks until a user joins a group or views the member list to avoid excessive fanout.

![Presence status fanout](https://nextleet.com/images/presence-status-fanout.png)

 

### Failure handling and operational concerns

Key operational considerations:

- If a chat server fails, service discovery (e.g., ZooKeeper) should help reassign new connections to healthy servers; persist connection metadata so reconnection/resumption is possible.
- Persist messages to a durable store via a message-sync queue before acknowledging senders to avoid data loss.
- Use retries and dead-letter queues for failed persistence or delivery attempts.
- Monitor metrics: connection counts, message latency, queue lengths, error rates, and presence heartbeat loss.

Consider geo-distribution for latency: route users to nearby datacenters and replicate user metadata appropriately. Decide on consistency model: relaxed eventual consistency (typical) vs strict consistency (more expensive).

 

## Step 4 - Wrap up

We built a design supporting one-on-one and small group chats with WebSocket-based realtime delivery, service discovery for scalable connection assignment, presence servers, reliable persistence via message-sync queues and key-value storage for history, and push notification integration for offline users.

Additional topics worth discussing if time permits:

- Support for media (images, video, voice): requires compression, cloud storage for blobs, thumbnails, and CDN integration.
- End-to-end encryption: ensures only sender and receiver can read messages (adds complexity for search and multi-device sync).
- Client-side caching to reduce server load and speed up UI.
- Geographically distributed caches and data to reduce load times (Slack-style approaches).
- Robust error handling and message resend/retry mechanisms.
- Graceful handover of connections if a chat server goes down (coordination via ZooKeeper/etcd).

When presenting this design in an interview, always state your assumptions, explain trade-offs (latency vs. availability, storage cost vs. retention), and focus on the key components that demonstrate your understanding of distributed realtime systems.