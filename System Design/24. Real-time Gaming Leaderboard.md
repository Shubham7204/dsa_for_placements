
We are going to design a leaderboard for an online mobile game.

![leaderboard](https://nextleet.com/images/leaderboard.png)

Ask AI

## Step 1 - Understand the Problem and Establish Design Scope

- **C:** How is the score calculated for the leaderboard?
- **I:** A user gets a point whenever they win a match.
- **C:** Are all players included in the leaderboard?
- **I:** Yes.
- **C:** Is there a time segment associated with the leaderboard?
- **I:** Each month, a new tournament starts, which begins a new leaderboard.
- **C:** Can we assume we only care about the top 10 users?
- **I:** We want to display the top 10 users, along with the position of a specific user. If time permits, we can discuss showing users around a particular user on the leaderboard.
- **C:** How many users are in a tournament?
- **I:** 5 million DAU and 25 million MAU.
- **C:** How many matches are played on average during a tournament?
- **I:** Each player plays 10 matches per day on average.
- **C:** How do we determine the rank if two players have the same score?
- **I:** Their rank is the same in that case. If time permits, we can discuss breaking ties.
- **C:** Does the leaderboard need to be real-time?
- **I:** Yes, we want to present real-time results or as close as possible to real-time. It is not okay to present batched result history.

Ask AI

### Functional requirements

- Display top 10 players on a leaderboard.
- Show a user's specific rank.
- Display users which are four places above and below a given user (bonus).

### Non-functional requirements

- Real-time updates on scores.
- Score updates are reflected on the leaderboard in real-time.
- General scalability, availability, reliability.

Ask AI

### Back-of-the-envelope estimation

With 50 million DAU, if the game has an even distribution of players during a 24-hour period, we'd have an average of 50 users per second. Peak online users are estimated at 250 users per second.

QPS for users scoring a point - given 10 games per day on average, 50 users/s * 10 = 500 QPS. Peak QPS = 2500.

QPS for fetching the top 10 leaderboard - assuming users open that once a day on average, QPS is ~50.

Ask AI

## Step 2 - Propose High-Level Design and Get Buy-In

We'll propose APIs, a high-level architecture, and evaluate storage options (RDBMS, Redis, NoSQL).

Ask AI

### API Design

Update score API (only game servers should call):

```
POST /v1/scores
{
  "user_id": "user123",
  "points": 1
}
```

Get top leaderboard:

```
GET /v1/scores
Response: {
  "data": [
    {"user_id":"user_id1","user_name":"alice","rank":1,"score":12543},
    ...
  ],
  "total": 10
}
```

Get a user's score & rank:

```
GET /v1/scores/{:user_id}
Response: {
  "user_info": {"user_id":"user5","score":1000,"rank":6}
}
```

Ask AI

### High-level architecture

![high-level-architecture](https://nextleet.com/images/high-level-architecture.png)

- A player wins -> The game server validates the win and calls the Leaderboard service.
- The Leaderboard service updates the leaderboard store.
- Clients query the leaderboard service for top-K or user rank.

Alternative (insecure): allowing clients to update the leaderboard directly is vulnerable to cheating. Always trust server-to-server updates.

Ask AI

### Data models & storage options

#### Relational database solution

A simple table per leaderboard (or use a month column). On a score update: INSERT (if new) or UPDATE score. A Top-K query requires ORDER BY score DESC LIMIT K - this is expensive at a large scale and not ideal for frequent real-time updates.

#### Redis solution (recommended)

Use Redis sorted sets (ZSET) where member=user_id and score=score. Redis operations:

- `ZADD` - add or update a user with a score.
- `ZINCRBY` - increment a user's score.
- `ZREVRANGE` - fetch top-K with scores.
- `ZREVRANK` / `ZREVRANGE` - fetch a user's rank and neighbors.

Example: `ZINCRBY leaderboard_feb_2021 1 'mary1934'` and `ZREVRANGE leaderboard_feb_2021 0 9 WITHSCORES`.

Storage estimate: 25M users * ~26 bytes = ~650MB (fits a single Redis node; plan replicas/persistence).

#### NoSQL alternative

Use DynamoDB/Cassandra with score as the sort key and month/partitioning for write sharding. This works for extreme scale but is harder to compute global top-K and per-user rank; it requires scatter-gather or periodic aggregation jobs.

Ask AI

### Operational considerations (Redis specifics)

Use Redis replicas and persistence (RDB/AOF) to avoid data loss. Have a warm-failover strategy (sentinel or managed Redis service) and backups to reconstruct from an authoritative source (MySQL WAL or game events).

If the userbase grows 10x, shard/partition Redis. Options:

- Range partitioning by score buckets - simpler top-K retrieval but requires mapping user->shard.
- Hash partitioning (Redis Cluster) - automatic distribution; top-K requires fetching top-K from each shard and merging.

Merging top-K across many shards increases latency. For heavy scale, maintain a small in-memory global aggregator (e.g., every few seconds) that stores the merged top-K for fast reads.

Ask AI

## Step 3 - Design Deep Dive

Deep dive topics: cloud vs. self-hosted, scaling Redis, NoSQL design trade-offs, tie-breaking, and failure recovery.

Ask AI

### Cloud vs self-hosted

Serverless/cloud-managed (e.g., managed Redis, AWS Lambda) reduces the ops burden and scales quickly. Use managed Redis or DynamoDB when you want operational simplicity.

Self-hosted gives control and potential cost advantages, but requires operational expertise to manage sharding, failover, and monitoring.

Ask AI

### Scaling Redis (detailed)

For current estimates (25M MAU participating), a single Redis cluster can be sufficient. For 10x growth you must shard.

Range partition: partition by score ranges; easiest for top-K (query the highest range). Need to handle hot ranges if scores cluster.

Hash partition (Redis Cluster): automatic distribution. To compute a global top-K you must get top-K from every shard and merge; this is scatter-gather.

Best practice: for a large scale, combine sharding with a periodic aggregator (every second/5s) that produces a global top-K snapshot stored in a fast cache - reads go to a snapshot; writes update shards in real-time.

Ask AI

### NoSQL alternative (detailed)

DynamoDB/Cassandra approach: partition writes using write-sharding (user_id % N). Store score as a sort key inside each partition. To fetch top-K you must query multiple partitions and merge results - use scatter-gather or maintain precomputed aggregates.

If exact rank is hard, consider returning a percentile (e.g., top 10%, 90th percentile) computed periodically.

Ask AI

### Additional considerations

- **Tie-breaking:** When scores tie, show equal rank. Optionally break ties by last-played timestamp (earlier wins rank higher) or user_id as a deterministic fallback.
- **Caching:** Cache top-K and hot user windows (user +/- 4 ranks) for very fast reads.
- **Event sourcing / durable log:** Persist scoring events to a durable event log (Kafka) so you can rebuild leaderboards after failures or for analytics.
- **Real-time pushes:** Use WebSockets or pub/sub to push leaderboard updates to clients for near-real-time UX.
- **Failure recovery:** On a large Redis outage, rebuild by replaying game events from a durable store or MySQL WAL and recomputing ZSET.

Ask AI

## Step 4 - Wrap Up

Recommended design summary:

- Use Redis sorted sets for real-time leaderboard storage and operations (ZINCRBY, ZREVRANGE, ZREVRANK).
- Keep an authoritative event log (Kafka) to reconstruct leaderboards if needed.
- Cache top-K snapshots and hot ranges to serve reads at low latency.
- Shard Redis for a large scale; use a periodic global aggregator to compute a fast global top-K.
- Consider NoSQL (DynamoDB/Cassandra) only if you must avoid in-memory store constraints - accept trade-offs around computing rank/top-K.

When presenting this design, state assumptions (top-K size, update QPS), discuss trade-offs (accuracy vs. latency, memory vs. compute), and highlight operational recovery strategies.