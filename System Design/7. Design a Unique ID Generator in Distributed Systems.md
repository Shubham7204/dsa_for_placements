We need to design a unique ID generator that works well in distributed systems.

A database primary key using `AUTO_INCREMENT` won't work across multiple database servers because coordination or leader-election introduces high latency and becomes a bottleneck.

The generator must be scalable, low-latency, and tolerant of faults typical in distributed environments.

 

## Step 1 - Understand the Problem and Establish Design Scope

Ask and clarify requirements before designing. Example Q&A from the interview:

- **Candidate:** What characteristics should the unique IDs have?
- **Interviewer:** They should be unique and sortable.
- **Candidate:** For each record, does the ID increment by 1?
- **Interviewer:** IDs increase with time, but not necessarily by 1 for every record.
- **Candidate:** Do IDs contain only numerical values?
- **Interviewer:** Yes.
- **Candidate:** What is the ID length requirement?
- **Interviewer:** 64 bits.
- **Candidate:** What's the system scale?
- **Interviewer:** The system should be able to generate 10,000 IDs per second.

Key takeaways: IDs must be numeric, time-sortable, 64-bit, and generate approximately 10k per second per cluster (or per design target). Also confirm latency and availability constraints and whether strong monotonicity is required across all nodes.

 

## Step 2 - Propose High-Level Design and Get Buy-In

We consider four main approaches: multi-master auto-increment, UUIDs, a ticket server, and the Twitter Snowflake pattern. Each has trade-offs.

### Multi-Master Replication

Use database auto_increment but stride by K, where K = number of masters (or use server-specific offsets). Example: server i issues IDs like `i, i+K, i+2K, ...`

![multi master replication](https://nextleet.com/images/multi-master-replication.png)

- Pros: Simple to implement and uses DB guarantees without extra coordination for each ID generation.
- Cons: Hard to scale across data centers; IDs do not necessarily increase strictly by time globally; adding or removing servers breaks stride allocation unless carefully rebalanced.

### UUID

Universally Unique IDs (UUIDs) are 128-bit identifiers that can be generated independently on every machine with negligible collision probability.

- Pros: No coordination required, easy to scale.
- Cons: UUIDs are 128-bit (not 128-byte), do not fit the 64-bit requirement, are not numeric-only in some representations, and are not time-sortable by default (unless you use a time-ordered UUID variant).

### Ticket Server

A centralized ticket server hands out numeric IDs on request.

![ticket server](https://nextleet.com/images/ticket-server.png)

- Pros: Numeric IDs, simple to implement, works well for small to medium scale.
- Cons: Single point of failure unless made highly available; network round-trip adds latency; the ticket service itself needs to scale and be protected from overload.

### Twitter Snowflake

Snowflake addresses requirements: numeric 64-bit IDs, time-ordered (sortable), and can be generated independently by each server with minimal coordination (only for worker or node IDs).

![twitter snowflake](https://nextleet.com/images/twitter-snowflake.png)

Typical Snowflake 64-bit layout (one standard variant):

```
0 (sign bit) | 41-bit timestamp (ms since custom epoch) | 5-bit datacenter id | 5-bit machine id | 12-bit sequence number
```

- Pros: 64-bit numeric IDs, roughly monotonic (sortable by time), extremely fast, decentralized ID generation, supports bursts via sequence number.
- Cons: Requires provisioning unique datacenter and machine IDs; handling clock skew and clock rollback needs care; sequence bits constrain per-node throughput within a millisecond (but can be tuned).

Given the requirements (64-bit, time-sortable, high throughput, distributed), **Snowflake** is the best fit in most cases. We'll deep-dive into Snowflake next.

 

## Step 3 - Design Deep Dive (Snowflake)

We adopt the Snowflake approach. Key elements: timestamp, datacenter id, machine id, and sequence.

### Bit Layout and Capacity

Using the standard split gives us:

- 1 sign bit (always 0)
- 41 bits for timestamp in milliseconds, about 69 years of usable time from a chosen epoch
- 5 bits for datacenter id, up to 32 data centers
- 5 bits for machine id, up to 32 machines per data center
- 12 bits for sequence, up to 4096 IDs per machine per millisecond

With 12 sequence bits, one machine can generate up to 4,096 IDs per millisecond, approximately 4M IDs per second worst-case per machine. This comfortably covers 10k IDs per second system-wide with many machines, and gives ample headroom for bursts.

### ID Generation Algorithm (Pseudocode)

```
function nextId() {
  now = current_millis()
  if now < lastTimestamp:
    // clock moved backwards
    if (lastTimestamp - now) < maxBackwardMs:
      wait until now >= lastTimestamp
    else:
      // take corrective action: fail, use alternate epoch, or use an allocated emergency worker id
  if now == lastTimestamp:
    sequence = (sequence + 1) & sequenceMask
    if sequence == 0:
      // sequence overflow within same ms
      now = waitUntilNextMillis(lastTimestamp)
  else:
    sequence = 0
  lastTimestamp = now
  id = ((now - customEpoch) << timestampShift)
       | (datacenterId << datacenterShift)
       | (machineId << machineShift)
       | sequence
  return id
}
```

Notes: Choose a stable custom epoch, calculate shifts as cumulative bit widths, and ensure datacenterId and machineId are unique per host.

### Worker and Machine ID Assignment

Possible ways to assign unique machine IDs at startup:

- Static configuration (ops assigns each machine a unique id)
- Use a coordination service (Zookeeper or etcd) to lease an id at startup
- Use DHCP-based hooks or cloud metadata (e.g., instance metadata) in controlled environments

### Clock Synchronization and Backward Time

Keep clocks fairly synchronized (NTP) but do not rely on perfect sync. Handle backward clock movement by either waiting, using a reserved worker id, or storing a small persistent offset. For extreme safety, prefer waiting a short time rather than risking duplicate IDs.

### Sequence Overflow Strategies

If a machine exhausts the sequence space within the same millisecond (sequence overflow), strategies include:

- Wait until next millisecond (simple and common).
- Return an error to the caller (when low-latency requirements prefer this).
- Increase sequence bits at the cost of timestamp bits if longer lifetime is less important.

### High Availability

Make ID generators more available by running many generators with unique machine IDs; clients should be able to fall back to other generators. Avoid centralized ticket servers if you want minimal latency per ID.

 

## Step 4 - Wrap Up and Operational Considerations

We explored multiple options and converged on the Snowflake design as it best meets the constraints: 64-bit numeric IDs, time-sortable, decentralized generation, and high throughput.

### Operational Points

- Clock synchronization (NTP): Keep clocks stable and monitor for clock drift; add alarms for large jumps.
- Worker id allocation: Use a reliable mechanism (static ops config or a lease-based system like Zookeeper or etcd) to avoid id collisions.
- Monitoring and alerts: Monitor time skew, sequence exhaustion events, and generator errors.
- Testing and rollout: Test new bit allocations and epoch changes in staging first; ensure backwards compatibility if clients persist IDs.

### Tuning Ideas

- If you need more per-ms throughput per node, reduce timestamp bits and increase sequence bits (trade lifetime for throughput).
- Choose a custom epoch to extend usable timestamp range in future (or to save timestamp bits today).
- To harden availability, run multiple generators per datacenter and ensure clients retry on failure.

Final note: Unique ID generation is a critical infrastructure component. Design it conservatively, automate machine-id assignment, monitor closely, and prefer simple, well-tested techniques (like Snowflake) unless special constraints require otherwise.